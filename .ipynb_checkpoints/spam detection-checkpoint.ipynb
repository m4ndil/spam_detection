{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e99407d-f5ad-4087-92a4-acccdd6ea72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8141794b-6cad-48ec-9702-ec1417fc18f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('kaggle dataset.csv', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d87433-e08f-4c12-af88-01243ef00c14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9054b55-6eab-47a9-960a-3276ec2bf911",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891a086c-c6c0-466c-8ab3-08a45bfc5e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f9786b-256c-4033-bae0-36a62a6e5542",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = df.index + 1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408870ca-76b1-4eeb-981c-88b008ff386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unnecessary_columns = [\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"]\n",
    "df.drop(columns = unnecessary_columns, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7386140d-4acc-407b-a842-66935908ae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa26132-e039-4c39-8b7e-26c54780163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772a9f31-276f-44fc-9fb4-2de34abae824",
   "metadata": {},
   "outputs": [],
   "source": [
    "readable_columns = {\"v1\":\"Label\",\"v2\":\"Content\"}\n",
    "df.rename(columns = readable_columns,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc09de1-4b83-45f5-8cfd-0143eec6a2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6906e9-80df-4836-a267-360d893be699",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82babf2d-85fb-4c17-8d99-de0b430b0cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d92179-518e-4779-a81d-d232a93075e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783e7695-acc9-4f54-b7ce-9fcf8e843422",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a974b48-1a3c-4213-94c2-d01e438f9423",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56c7b7e-8793-48d9-ad6e-79f0bba05e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a2c2e9-9afd-45ca-990d-dbd1dec05f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599de49e-7f31-4ec5-929e-1593ab1fd11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: Convert labels to binary (0 for ham, 1 for spam)\n",
    "df['Label'] = df['Label'].apply(lambda x: 1 if x == 'spam' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92cb5f7-1877-4646-9695-9907216b5e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef7fd3d-5707-4c8a-847d-607ac3792bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7887cf64-fa12-4a19-b7ab-bf3477252453",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_count = (df['Label'] == 1).sum()\n",
    "ham_count = (df['Label'] == 0).sum()\n",
    "\n",
    "print(f\"Total Spam Count: {spam_count}\")\n",
    "print(f\"Total Ham Count: {ham_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74309f06-8474-4bef-ae83-7f9862a4aee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed9af30-ba36-4b61-a31f-75b7ab4ff127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15381c9c-4227-4ba4-bf40-8dae16b2cc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#autopct=\"%0.2f\" shows %\n",
    "colors = ['#00ff00', '#ff0000']\n",
    "plt.pie(df['Label'].value_counts(), labels=['HAM', 'SPAM'], autopct=\"%0.2f\", colors=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b89cbc1-f751-40bb-9264-af3277ef9d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data is not balanced it leans towards ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3449b424-995e-4d89-8b5b-28597490c89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2007691a-69f5-45f6-8a22-3370df2ab05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278214d8-2a45-47cf-bd9b-d624bb40895b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f6320f-7b75-4568-8db0-1721e8a0ee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentence Count'] = df['Content'].apply(lambda x:len(nltk.sent_tokenize(x)))\n",
    "df['Word Count'] = df['Content'].apply(lambda x:len(nltk.word_tokenize(x)))\n",
    "df['Character Count'] = df['Content'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ca0580-b1e8-4612-b49d-7b8397c4ac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f33382-9260-4ee6-a8a9-f12741abfa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ada741b-fe40-4d60-9dcb-29b230ea52e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Label'] == 0][['Sentence Count','Word Count','Character Count']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144abb15-f17c-4cdd-b4ef-ad31f7691c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Label'] == 1][['Sentence Count','Word Count','Character Count']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3412b70f-2c6a-44d5-846e-47b8294479bc",
   "metadata": {},
   "outputs": [],
   "source": [
    " df[['Sentence Count','Word Count','Character Count']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a8a249-dbd9-48fa-a1f1-85c62e6ce415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a56319-a53a-41ff-92f9-2604645cef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.histplot(df[df['Label'] == 0]['Sentence Count'],color='#00ff00')\n",
    "sns.histplot(df[df['Label'] == 1]['Sentence Count'],color='#ff0000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917d6d44-cac2-45cd-aec1-5ce18bd1fb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "sns.histplot(df[df['Label'] == 0]['Word Count'],color='#00ff00')\n",
    "sns.histplot(df[df['Label'] == 1]['Word Count'],color='#ff0000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d74b81d-4070-49ef-8cd4-ff662fa624f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "sns.histplot(df[df['Label'] == 0]['Character Count'],color='#00ff00')\n",
    "sns.histplot(df[df['Label'] == 1]['Character Count'],color='#ff0000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aab23a9-b213-4307-bf4a-acd26f0fc222",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df,hue='Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f47b86-7843-4f41-bbd3-47e9fc6a114c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#autopct=\"%0.2f\" shows %\n",
    "colors = ['#00ff00', '#ff0000']\n",
    "plt.pie(df['Label'].value_counts(), labels=['HAM', 'SPAM'], autopct=\"%0.2f\", colors=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14064fd9-b4d2-4f3a-b227-aa65016c884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the DataFrame into two groups based on the 'spam' column\n",
    "df_0 = df[df['Label'] == 0] # The group with spam value 0\n",
    "df_1 = df[df['Label'] == 1] # The group with spam value 1\n",
    "\n",
    "# Find the number of rows in the smaller group\n",
    "n = min(len(df_0), len(df_1))\n",
    "\n",
    "# Sample n rows from the larger group without replacement\n",
    "df_0_balanced = df_0.sample(n, replace=False)\n",
    "\n",
    "# Concatenate the balanced group with the smaller group\n",
    "df_balanced = pd.concat([df_0_balanced, df_1])\n",
    "df = df_balanced\n",
    "# Print the balanced DataFrame\n",
    "print(df_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825dd23f-4e28-4047-aea4-49ce54599843",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ecbf0a-59cc-4947-a553-336b3149c2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#autopct=\"%0.2f\" shows %\n",
    "colors = ['#00ff00', '#ff0000']\n",
    "plt.pie(df['Label'].value_counts(), labels=['HAM', 'SPAM'], autopct=\"%0.2f\", colors=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca8c307-ce67-48ff-ab09-a6776aa6bc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c565c68f-8386-4291-9a8e-d58912f86f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "ps.stem('loving')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b33fe4-2a91-4681-babb-b0f1dfb6e913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3deb6cc-a727-4a44-9efa-7485061f8929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def transform_text(text):\n",
    "    text = text.lower()\n",
    "    text = nltk.word_tokenize(text)\n",
    "    \n",
    "    y = []\n",
    "    for i in text:\n",
    "        if i.isalnum():\n",
    "            y.append(i)\n",
    "    \n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    \n",
    "    for i in text:\n",
    "        if i not in stopwords.words('english') and i not in string.punctuation:\n",
    "            y.append(i)\n",
    "            \n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    \n",
    "    for i in text:\n",
    "        y.append(ps.stem(i))\n",
    "    \n",
    "            \n",
    "    return \" \".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bc2c95-c64d-4585-832b-2a7b8e2dc7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "df['Content'][69]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a110dc00-727d-4747-8eb6-4855e08a3a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_text(df['Content'][69])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa481e88-5d2a-459d-9d0f-7b528fb81f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Revised Content'] = df['Content'].apply(transform_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceec9910-5740-4957-967f-66a5bfd803f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e3ca87-f1a2-4ddc-bc67-bdc495636ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1b1a8b-1227-4b2e-8be9-9afe27dc31a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "wc = WordCloud(width=500,height=500,min_font_size=10,background_color='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780e1112-1506-41a1-886b-3e983c3daa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_wc = wc.generate(df[df['Label'] == 1]['Revised Content'].str.cat(sep=\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e6531f-cd94-476e-b7c5-41358700abd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.imshow(spam_wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb533c7-a245-4e43-874a-c1b510784886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c68f54-3ae2-4d99-b01b-63259c077af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' is your DataFrame with 'transformed_text' column and 'target' column\n",
    "spam_text = df[df['Label'] == 1]['Revised Content'].str.cat(sep=\" \")\n",
    "\n",
    "# Create a Counter object to count word frequencies\n",
    "word_counts = Counter(spam_text.split())\n",
    "\n",
    "# Get the most common words and their frequencies\n",
    "top_words = word_counts.most_common(10)  # You can adjust the number based on your preference\n",
    "\n",
    "# Extract words and frequencies for plotting\n",
    "words, frequencies = zip(*top_words)\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.bar(words, frequencies, color='skyblue')\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Top 10 Words in Spam Text')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8101fe3-2587-417c-877e-0131b61a3ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_wc = wc.generate(df[df['Label'] == 0]['Revised Content'].str.cat(sep=\" \"))\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.imshow(ham_wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07335f3-5196-4cff-af5f-6d79bd622ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' is your DataFrame with 'transformed_text' column and 'target' column\n",
    "ham_text = df[df['Label'] == 0]['Revised Content'].str.cat(sep=\" \")\n",
    "\n",
    "# Create a Counter object to count word frequencies\n",
    "word_counts = Counter(ham_text.split())\n",
    "\n",
    "# Get the most common words and their frequencies\n",
    "top_words = word_counts.most_common(10)  # You can adjust the number based on your preference\n",
    "\n",
    "# Extract words and frequencies for plotting\n",
    "words, frequencies = zip(*top_words)\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.bar(words, frequencies, color='skyblue')\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Top 10 Words in Spam Text')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec786ce1-2621-44cc-8215-6019bea0feed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78565402-f112-4337-96b5-fc3453781303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "cv = CountVectorizer()\n",
    "tfidf = TfidfVectorizer(max_features=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8436df-5608-4d92-9d2b-a79e36e1c682",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf.fit_transform(df['Revised Content']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccded75-fb97-4cf3-9b4d-d91a1b3abc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638d9e09-89b8-49e0-a2ba-8ca6ac52447c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30447f55-00bc-4ea8-812c-dfe56e1c199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5780cd-3c36-4250-b325-fb8c0343f6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561f318c-e1ad-46b8-af1a-eb247abc0ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,precision_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e55c3df-8482-4369-a0db-ab08346d7be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=5)\n",
    "knn = KNeighborsClassifier()\n",
    "gnb = GaussianNB()\n",
    "mnb = MultinomialNB()\n",
    "bnb = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713ff00b-8867-410a-89e4-26bb7631fd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.fit(X_train,y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "cm_dt = confusion_matrix(y_test,y_pred_dt)\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "\n",
    "# Print accuracy, precision, and confusion matrix for Decision Trees\n",
    "print(\"Decision Trees:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_dt))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_dt)\n",
    "\n",
    "# Generate classification report for Decison Trees\n",
    "report_dt = classification_report(y_test, y_pred_dt)\n",
    "print(\"\\nClassification Report for Decison Trees:\\n\", report_dt)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_dt, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])\n",
    "plt.title('confusion_matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c75492-cb00-4599-8611-dfd5d76112de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbors (KNN)\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "\n",
    "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "\n",
    "print(\"K-Nearest Neighbors:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_knn))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_knn)\n",
    "\n",
    "report_knn = classification_report(y_test, y_pred_knn)\n",
    "print(\"\\nClassification Report for K-Nearest Neighbors:\\n\", report_knn)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_knn, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])\n",
    "plt.title('Confusion Matrix - K-Nearest Neighbors')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0181bd48-722d-4463-9bd7-c1b3c1661a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes (GNB)\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred_gnb = gnb.predict(X_test)\n",
    "accuracy_gnb = accuracy_score(y_test, y_pred_gnb)\n",
    "\n",
    "\n",
    "cm_gnb = confusion_matrix(y_test, y_pred_gnb)\n",
    "\n",
    "print(\"Gaussian Naive Bayes:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_gnb))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_gnb))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_gnb)\n",
    "\n",
    "report_gnb = classification_report(y_test, y_pred_gnb)\n",
    "print(\"\\nClassification Report for Gaussian Naive Bayes:\\n\", report_gnb)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_gnb, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])\n",
    "plt.title('Confusion Matrix - Gaussian Naive Bayes')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2c0786-256f-49d6-ba75-bd5b796bd496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Naive Bayes (MNB)\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "y_pred_mnb = mnb.predict(X_test)\n",
    "accuracy_mnb = accuracy_score(y_test, y_pred_mnb)\n",
    "\n",
    "cm_mnb = confusion_matrix(y_test, y_pred_mnb)\n",
    "\n",
    "print(\"Multinomial Naive Bayes:\")\n",
    "print(\"Accuracy:\", accuracy_mnb)\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_mnb))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_mnb)\n",
    "\n",
    "report_mnb = classification_report(y_test, y_pred_mnb)\n",
    "print(\"\\nClassification Report for Multinomial Naive Bayes:\\n\", report_mnb)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_mnb, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])\n",
    "plt.title('Confusion Matrix - Multinomial Naive Bayes')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47a597c-3c6b-4733-a3a9-9b55768ae038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bernoulli Naive Bayes (BNB)\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "y_pred_bnb = bnb.predict(X_test)\n",
    "accuracy_bnb = accuracy_score(y_test, y_pred_bnb)\n",
    "\n",
    "cm_bnb = confusion_matrix(y_test, y_pred_bnb)\n",
    "\n",
    "print(\"Bernoulli Naive Bayes:\")\n",
    "print(\"Accuracy:\", accuracy_bnb)\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_bnb))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_bnb)\n",
    "\n",
    "report_bnb = classification_report(y_test, y_pred_bnb)\n",
    "print(\"\\nClassification Report for Bernoulli Naive Bayes:\\n\", report_bnb)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_bnb, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])\n",
    "plt.title('Confusion Matrix - Bernoulli Naive Bayes')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143ec6f3-db90-4306-9f68-8150d6504cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have calculated accuracy for each model\n",
    "accuracies = [accuracy_dt, accuracy_knn, accuracy_gnb, accuracy_mnb, accuracy_bnb]\n",
    "models = ['Decision Trees', 'K-Nearest Neighbors', 'Gaussian Naive Bayes', 'Multinomial Naive Bayes', 'Bernoulli Naive Bayes']\n",
    "colors = ['blue', 'green', 'orange', 'purple', 'red']\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "bars = plt.bar(models, accuracies, color=colors)\n",
    "\n",
    "# Adding legend\n",
    "plt.legend(bars, models, loc='upper left')\n",
    "\n",
    "plt.title('Model Comparison - Accuracy')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0.0, 1.0)  # Set the y-axis limit to ensure proper visualization of accuracy values\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7320e66-8257-4cd4-95f2-058e1d639d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameter grid with 10 values for each hyperparameter\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 9, 11, 13, 15, 17, 19, 21],\n",
    "    'min_samples_split': [2, 5, 10, 15, 20, 25, 30, 35, 40, 45],\n",
    "    'min_samples_leaf': [1, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to find the best hyperparameters\n",
    "grid_search = GridSearchCV(dt, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# No need to use set_params, the best model is already fitted\n",
    "best_dt = grid_search.best_estimator_\n",
    "y_pred_best_dt = best_dt.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the best model\n",
    "accuracy_best_dt = accuracy_score(y_test, y_pred_best_dt)\n",
    "precision_best_dt = precision_score(y_test, y_pred_best_dt)\n",
    "cm_best_dt = confusion_matrix(y_test, y_pred_best_dt)\n",
    "\n",
    "# Print evaluation metrics for the best model\n",
    "print(\"\\nBest Decision Tree Model:\")\n",
    "print(\"Accuracy:\", accuracy_best_dt)\n",
    "print(\"Precision:\", precision_best_dt)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_best_dt)\n",
    "\n",
    "# Visualize the confusion matrix for the best model\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_best_dt, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])\n",
    "plt.title('Confusion Matrix (Best Model)')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a700ec6b-8431-43ac-b152-98605aa27af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# K-Nearest Neighbors (KNN)\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Define the hyperparameter grid for KNN\n",
    "knn_param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]  # 1 for Manhattan distance, 2 for Euclidean distance\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to find the best hyperparameters for KNN\n",
    "knn_grid_search = GridSearchCV(knn, knn_param_grid, cv=5, scoring='accuracy')\n",
    "knn_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters for KNN\n",
    "best_knn_params = knn_grid_search.best_params_\n",
    "print(\"Best Hyperparameters for K-Nearest Neighbors:\", best_knn_params)\n",
    "\n",
    "# Use the best KNN model for predictions\n",
    "best_knn = knn_grid_search.best_estimator_\n",
    "y_pred_best_knn = best_knn.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the best KNN model\n",
    "accuracy_best_knn = accuracy_score(y_test, y_pred_best_knn)\n",
    "precision_best_knn = precision_score(y_test, y_pred_best_knn)\n",
    "cm_best_knn = confusion_matrix(y_test, y_pred_best_knn)\n",
    "\n",
    "# Print evaluation metrics for the best KNN model\n",
    "print(\"\\nBest K-Nearest Neighbors Model:\")\n",
    "print(\"Accuracy:\", accuracy_best_knn)\n",
    "print(\"Precision:\", precision_best_knn)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_best_knn)\n",
    "\n",
    "# Visualize the confusion matrix for the best KNN model\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_best_knn, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])\n",
    "plt.title('Confusion Matrix - Best K-Nearest Neighbors Model')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8903e4c8-d3e6-413c-a2e0-6646d8c57edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# K-Nearest Neighbors (KNN)\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Define the hyperparameter grid for KNN\n",
    "knn_param_grid = {\n",
    "    'n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]  # 1 for Manhattan distance, 2 for Euclidean distance\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to find the best hyperparameters for KNN\n",
    "knn_grid_search = GridSearchCV(knn, knn_param_grid, cv=5, scoring='accuracy')\n",
    "knn_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print accuracy for each hyperparameter combination\n",
    "results = pd.DataFrame(knn_grid_search.cv_results_)\n",
    "for index, row in results.iterrows():\n",
    "    print(\"Parameters:\", row['params'])\n",
    "    print(\"Mean Accuracy:\", row['mean_test_score'])\n",
    "    print(\"=====================================\")\n",
    "\n",
    "# Get the best hyperparameters for KNN\n",
    "best_knn_params = knn_grid_search.best_params_\n",
    "print(\"\\nBest Hyperparameters for K-Nearest Neighbors:\", best_knn_params)\n",
    "\n",
    "# Use the best KNN model for predictions\n",
    "best_knn = knn_grid_search.best_estimator_\n",
    "y_pred_best_knn = best_knn.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the best KNN model\n",
    "accuracy_best_knn = accuracy_score(y_test, y_pred_best_knn)\n",
    "precision_best_knn = precision_score(y_test, y_pred_best_knn)\n",
    "cm_best_knn = confusion_matrix(y_test, y_pred_best_knn)\n",
    "\n",
    "# Print evaluation metrics for the best KNN model\n",
    "print(\"\\nBest K-Nearest Neighbors Model:\")\n",
    "print(\"Accuracy:\", accuracy_best_knn)\n",
    "print(\"Precision:\", precision_best_knn)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_best_knn)\n",
    "\n",
    "# Visualize the confusion matrix for the best KNN model\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_best_knn, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])\n",
    "plt.title('Confusion Matrix - Best K-Nearest Neighbors Model')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aea981-3977-4c0c-9e7a-a02d12fd5c91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming X_train is your training data with 3390 features\n",
    "# Create a DecisionTreeClassifier instance\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# Define the hyperparameter grid with 10 values for each hyperparameter\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 9, 11, 13, 15, 17, 19, 21],\n",
    "    'min_samples_split': [2, 5, 10, 15, 20, 25, 30, 35, 40, 45],\n",
    "    'min_samples_leaf': [1, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to find the best hyperparameters\n",
    "grid_search = GridSearchCV(dt, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print accuracy for each hyperparameter combination\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "for index, row in results.iterrows():\n",
    "    print(\"Parameters:\", row['params'])\n",
    "    print(\"Mean Accuracy:\", row['mean_test_score'])\n",
    "    print(\"=====================================\")\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"\\nBest Hyperparameters:\", best_params)\n",
    "\n",
    "# Create a new DecisionTreeClassifier instance with the best hyperparameters\n",
    "best_dt = DecisionTreeClassifier(max_depth=best_params['max_depth'], \n",
    "                                 min_samples_split=best_params['min_samples_split'], \n",
    "                                 min_samples_leaf=best_params['min_samples_leaf'])\n",
    "\n",
    "# Train the best model with the full training data\n",
    "best_dt.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_best_dt = best_dt.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the best model\n",
    "accuracy_best_dt = accuracy_score(y_test, y_pred_best_dt)\n",
    "precision_best_dt = precision_score(y_test, y_pred_best_dt)\n",
    "cm_best_dt = confusion_matrix(y_test, y_pred_best_dt)\n",
    "\n",
    "# Print evaluation metrics for the best model\n",
    "print(\"\\nBest Decision Tree Model:\")\n",
    "print(\"Accuracy:\", accuracy_best_dt)\n",
    "print(\"Precision:\", precision_best_dt)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_best_dt)\n",
    "\n",
    "# Visualize the confusion matrix for the best model\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_best_dt, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])\n",
    "plt.title('Confusion Matrix (Best Model)')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f015db2e-ebdb-4742-91d1-c00d01f07267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Naive Bayes (MNB)\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "y_pred_mnb = mnb.predict(X_test)\n",
    "accuracy_mnb = accuracy_score(y_test, y_pred_mnb)\n",
    "\n",
    "cm_mnb = confusion_matrix(y_test, y_pred_mnb)\n",
    "\n",
    "print(\"Multinomial Naive Bayes:\")\n",
    "print(\"Accuracy:\", accuracy_mnb)\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_mnb))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_mnb)\n",
    "\n",
    "report_mnb = classification_report(y_test, y_pred_mnb)\n",
    "print(\"\\nClassification Report for Multinomial Naive Bayes:\\n\", report_mnb)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_mnb, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])\n",
    "plt.title('Confusion Matrix - Multinomial Naive Bayes')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6034a0c1-8a10-4c4d-8907-a09df9fc555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Accuracy scores for each model\n",
    "accuracy_scores = [accuracy_mnb, accuracy_best_dt, accuracy_best_knn]\n",
    "\n",
    "# Precision scores for each model\n",
    "precision_scores = [precision_score(y_test, y_pred_mnb),\n",
    "                    precision_best_dt,\n",
    "                    precision_best_knn]\n",
    "\n",
    "# Models' names\n",
    "models = ['Multinomial Naive Bayes', 'Best Decision Tree', 'Best K-Nearest Neighbors']\n",
    "\n",
    "# Bar graph for accuracy\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(models, accuracy_scores, color=['blue', 'green', 'orange'])\n",
    "plt.title('Model Comparison - Accuracy')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)  # Set the y-axis limit to better compare accuracies\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb141402-bb11-4b35-896f-496f6cc10c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar graph for precision\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(models, precision_scores, color=['blue', 'green', 'orange'])\n",
    "plt.title('Model Comparison - Precision')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim(0, 1)  # Set the y-axis limit to better compare precision\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feba1bd-6128-4292-804e-f8e7ab33b7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Vectorizer Vocabulary Size:\", len(loaded_vectorizer.vocabulary_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91234144-04d0-4f26-bdb2-e984b21d0179",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import joblib\n",
    "\n",
    "# Function for text transformation\n",
    "def transform_text(text):\n",
    "    text = text.lower()\n",
    "    text = nltk.word_tokenize(text)\n",
    "\n",
    "    y = []\n",
    "    for i in text:\n",
    "        if i.isalnum():\n",
    "            y.append(i)\n",
    "\n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "\n",
    "    for i in text:\n",
    "        if i not in stopwords.words('english') and i not in string.punctuation:\n",
    "            y.append(i)\n",
    "\n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "\n",
    "    for i in text:\n",
    "        y.append(ps.stem(i))\n",
    "\n",
    "    return \" \".join(y)\n",
    "\n",
    "# Load the saved vectorizer for prediction\n",
    "loaded_vectorizer = joblib.load('vectorizer.joblib')\n",
    "\n",
    "# Assuming df_balanced is already defined and contains 'Revised Content' column\n",
    "# Apply the same text transformation and vectorization\n",
    "X_text = loaded_vectorizer.transform(df_balanced['Revised Content'])\n",
    "\n",
    "# Decision Tree model\n",
    "# Assuming best_dt was trained using the original vectorizer\n",
    "# If not, you need to use the vectorizer that was used during training\n",
    "prediction_dt = best_dt.predict(X_text)\n",
    "\n",
    "# K-Nearest Neighbors model\n",
    "prediction_knn = best_knn.predict(X_text)\n",
    "\n",
    "# Multinomial Naive Bayes model\n",
    "prediction_mnb = mnb.predict(X_text)\n",
    "\n",
    "# Function to preprocess and predict\n",
    "def predict_spam_or_ham(text):\n",
    "    # Apply the same text transformation to the input text\n",
    "    preprocessed_text = transform_text(text)\n",
    "\n",
    "    # Transform the preprocessed text using the loaded vectorizer\n",
    "    X_text = loaded_vectorizer.transform([preprocessed_text])\n",
    "\n",
    "    # Use the Decision Tree model for prediction\n",
    "    prediction_dt = best_dt.predict(X_text)[0]\n",
    "\n",
    "    # Use the K-Nearest Neighbors model for prediction\n",
    "    prediction_knn = best_knn.predict(X_text)[0]\n",
    "\n",
    "    # Use the Multinomial Naive Bayes model for prediction\n",
    "    prediction_mnb = mnb.predict(X_text)[0]\n",
    "\n",
    "    # Return predictions\n",
    "    return {\n",
    "        'DecisionTree': 'Spam' if prediction_dt == 1 else 'Ham',\n",
    "        'KNearestNeighbors': 'Spam' if prediction_knn == 1 else 'Ham',\n",
    "        'MultinomialNaiveBayes': 'Spam' if prediction_mnb == 1 else 'Ham',\n",
    "    }\n",
    "\n",
    "# Example usage:\n",
    "text_to_predict = \"Check out this amazing offer! You've won a prize!\"\n",
    "predictions = predict_spam_or_ham(text_to_predict)\n",
    "\n",
    "print(\"Text:\", text_to_predict)\n",
    "print(\"Predictions:\")\n",
    "for model, result in predictions.items():\n",
    "    print(f\"{model}: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9c9f12-e658-42eb-bebb-25621df86798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf2727e-2386-44a9-8765-5008d1b40fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
